{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from flax import linen as nn\n",
    "from jax.nn.initializers import lecun_normal, normal\n",
    "from jax.numpy.linalg import eigh, inv, matrix_power\n",
    "from jax.scipy.signal import convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # For this tutorial, construct a global JAX rng key\n",
    "    # But we don't want it when importing as a library\n",
    "    rng = jax.random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_SSM(rng, N):\n",
    "    a_r, b_r, c_r = jax.random.split(rng, 3)\n",
    "    A = jax.random.uniform(a_r, (N, N))\n",
    "    B = jax.random.uniform(b_r, (N, 1))\n",
    "    C = jax.random.uniform(c_r, (1, N))\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[0.11888373, 0.02597141, 0.25442433, 0.03801537, 0.26417494],\n",
       "        [0.06834555, 0.76109946, 0.6487949 , 0.3947618 , 0.49821746],\n",
       "        [0.7629558 , 0.7416612 , 0.1261679 , 0.7579925 , 0.25363898],\n",
       "        [0.85696733, 0.82389295, 0.81947005, 0.5853926 , 0.54250216],\n",
       "        [0.35728765, 0.7542579 , 0.32637298, 0.85206413, 0.24110329]],      dtype=float32),\n",
       " Array([[0.79785824],\n",
       "        [0.73702896],\n",
       "        [0.4746939 ],\n",
       "        [0.32407498],\n",
       "        [0.84053826]], dtype=float32),\n",
       " Array([[0.34117317, 0.8346112 , 0.31955123, 0.50551903, 0.6800754 ]],      dtype=float32))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_SSM(rng, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(A, B, C, step):\n",
    "    I = np.eye(A.shape[0])\n",
    "    BL = inv(I - (step / 2.0) * A)\n",
    "    Ab = BL @ (I + (step / 2.0) * A)\n",
    "    Bb = (BL * step) @ B\n",
    "    return Ab, Bb, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_SSM(Ab, Bb, Cb, u, x0, verbose=False):\n",
    "    def step(x_k_1, u_k):\n",
    "        x_k = Ab @ x_k_1 + Bb @ u_k\n",
    "        y_k = Cb @ x_k\n",
    "\n",
    "        if verbose:\n",
    "            jax.debug.print(\"Ab: {}\", Ab)\n",
    "            jax.debug.print(\"Bb: {}\", Bb)\n",
    "            jax.debug.print(\"x_k-1: {}\", x_k_1)\n",
    "            jax.debug.print(\"u_k: {}\", u_k)\n",
    "            jax.debug.print(\"x_k = Ab @ x_k_1 + Bb @ u_k: {}\", x_k)\n",
    "            jax.debug.print(\"y_k = Cb @ x_k: {}\", y_k)\n",
    "            jax.debug.print(\"---------\")\n",
    "        return x_k, y_k\n",
    "\n",
    "    return jax.lax.scan(step, x0, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_SSM(A, B, C, u, verbose=True):\n",
    "    L = u.shape[0]\n",
    "    N = A.shape[0]\n",
    "    Ab, Bb, Cb = discretize(A, B, C, step=1.0 / L)\n",
    "\n",
    "    # Run recurrence\n",
    "    return scan_SSM(Ab, Bb, Cb, u[:, np.newaxis], np.zeros((N,)), verbose=verbose)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 5, 11], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1, 2], [3, 4]]) @ np.array([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_conv(Ab, Bb, Cb, L):\n",
    "    return np.array(\n",
    "        [(Cb @ matrix_power(Ab, l) @ Bb).reshape() for l in range(L)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = random_SSM(rng, 20)\n",
    "L = 1\n",
    "Ab, Bb, Cb = discretize(A, B, C, step=1.0 / L)\n",
    "\n",
    "K = K_conv(Ab, Bb, Cb, L=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-1.2262875,  1.8903167, -4.297544 ], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ -1.2262875 ,  -0.56225824,  -4.195773  ,  -7.829288  ,\n",
       "        -5.3313646 , -17.190176  ], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.array([1, 2, 3, 4])\n",
    "\n",
    "convolve(u, K, mode=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.4235166, -1.3600439, -7.6374397, -5.894321 ], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ud = np.fft.rfft(np.pad(u, (0, K.shape[0])))\n",
    "Kd = np.fft.rfft(np.pad(K, (0, u.shape[0])))\n",
    "out = ud * Kd\n",
    "np.fft.irfft(out)[: u.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1, 2, 3, 4, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(u, (0, K.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([-1.2262875,  1.8903167, -4.297544 ], dtype=float32),\n",
       " Array([-3.633515 +0.j       ,  0.9085992+2.7118864j,\n",
       "         2.2250307-3.707557j , -5.608879 -4.180133j ], dtype=complex64))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K, Kd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([10.        +0.j       , -2.0244584 -6.223982j ,\n",
       "        0.34601068+2.4791214j,  0.1784479 -2.4219847j], dtype=complex64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fft.rfft(np.pad(u, (0, K.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([1, 2, 3, 4], dtype=int32),\n",
       " Array([10.        +0.j       , -2.0244584 -6.223982j ,\n",
       "         0.34601068+2.4791214j,  0.1784479 -2.4219847j], dtype=complex64))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_convolution(u, K, nofft=False):\n",
    "    if nofft:\n",
    "        return convolve(u, K, mode=\"full\")[: u.shape[0]] # removes the addition results when K slides off the end of u\n",
    "    else:\n",
    "        assert K.shape[0] == u.shape[0]\n",
    "        ud = np.fft.rfft(np.pad(u, (0, K.shape[0])))\n",
    "        Kd = np.fft.rfft(np.pad(K, (0, u.shape[0])))\n",
    "        out = ud * Kd\n",
    "        return np.fft.irfft(out)[: u.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN: [[0.01893413]\n",
      " [0.02310157]\n",
      " [0.05276325]\n",
      " [0.08760231]\n",
      " [0.11060267]\n",
      " [0.14200173]\n",
      " [0.16301736]\n",
      " [0.19073845]\n",
      " [0.22022295]\n",
      " [0.25288185]\n",
      " [0.2983596 ]\n",
      " [0.345329  ]\n",
      " [0.42143378]\n",
      " [0.48412403]\n",
      " [0.55174446]\n",
      " [0.66502684]]\n",
      "CNN: [0.01893416 0.02310163 0.05276331 0.08760233 0.11060268 0.14200175\n",
      " 0.16301738 0.19073848 0.2202229  0.25288185 0.2983596  0.345329\n",
      " 0.42143366 0.4841239  0.55174434 0.66502666]\n"
     ]
    }
   ],
   "source": [
    "def test_cnn_is_rnn(N=4, L=16, step=1.0 / 16):\n",
    "    ssm = random_SSM(rng, N)\n",
    "    u = jax.random.uniform(rng, (L,))\n",
    "    jax.random.split(rng, 3)\n",
    "    # RNN\n",
    "    rec = run_SSM(*ssm, u, verbose=False)\n",
    "\n",
    "    # CNN\n",
    "    ssmb = discretize(*ssm, step=step)\n",
    "    conv = causal_convolution(u, K_conv(*ssmb, L))\n",
    "\n",
    "    print(\"RNN:\", rec)\n",
    "    print(\"CNN:\", conv)\n",
    "\n",
    "    # Check\n",
    "    assert np.allclose(rec.ravel(), conv.ravel())\n",
    "\n",
    "test_cnn_is_rnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â An SSM neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.83079386, 0.1660409 , 0.8430486 ],\n",
       "       [0.6428884 , 0.56865394, 0.6144446 ]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.random.uniform(rng, (2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_step_initializer(dt_min=0.001, dt_max=0.1):\n",
    "    def init(key, shape):\n",
    "        return jax.random.uniform(key, shape) * (\n",
    "            np.log(dt_max) - np.log(dt_min)\n",
    "        ) + np.log(dt_min)\n",
    "\n",
    "    return init\n",
    "\n",
    "\n",
    "def causal_convolution(u, K, nofft=False):\n",
    "    if nofft:\n",
    "        return convolve(u, K, mode=\"full\")[: u.shape[0]] # removes the addition results when K slides off the end of u\n",
    "    else:\n",
    "        assert K.shape[0] == u.shape[0]\n",
    "        ud = np.fft.rfft(np.pad(u, (0, K.shape[0])))\n",
    "        Kd = np.fft.rfft(np.pad(K, (0, u.shape[0])))\n",
    "        out = ud * Kd\n",
    "        return np.fft.irfft(out)[: u.shape[0]]\n",
    "\n",
    "class SSMLayer(nn.Module):\n",
    "    N: int # hidden state dimension\n",
    "    l_max: int # max seq length\n",
    "    decode: bool = False # Are we in the RNN mode?\n",
    "\n",
    "    # THIS setup is called each time parameters are updated(?)\n",
    "    def setup(self):\n",
    "\n",
    "        # SSM parameters\n",
    "        self.A = self.param(\"A\", lecun_normal(), (self.N, self.N))\n",
    "        self.B = self.param(\"B\", lecun_normal(), (self.N, 1))\n",
    "        self.C = self.param(\"C\", lecun_normal(), (1, self.N))\n",
    "        self.D = self.param(\"D\", nn.initializers.ones, (1,))\n",
    "\n",
    "        # Step parameter\n",
    "        self.log_step = self.param(\"log_step\", log_step_initializer(), (1,))\n",
    "\n",
    "        step = np.exp(self.log_step)\n",
    "        self.ssm = discretize(self.A, self.B, self.C, step=step)\n",
    "        self.K = K_conv(*self.ssm, self.l_max)\n",
    "\n",
    "        # RNN cache for long sequences\n",
    "        self.x_k_1 = self.variable(\"cache\", \"cache_x_k\", np.zeros, (self.N,))\n",
    "\n",
    "    def __call__(self, u):\n",
    "        if not self.decode:\n",
    "            # CNN Mode\n",
    "            return causal_convolution(u, self.K) + self.D * u\n",
    "        else:\n",
    "            # RNN Mode\n",
    "            x_k, y_s = scan_SSM(*self.ssm, u[:, np.newaxis], self.x_k_1.value)\n",
    "            if self.is_mutable_collection(\"cache\"):\n",
    "                self.x_k_1.value = x_k\n",
    "            return y_s.reshape(-1).real + self.D * u\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class SequenceBlock(nn.Module):\n",
    "    layer_cls: nn.Module\n",
    "    layer: dict  # Hyperparameters of inner layer\n",
    "    dropout: float\n",
    "    d_model: int\n",
    "    prenorm: bool = True\n",
    "    glu: bool = True\n",
    "    training: bool = True\n",
    "    decode: bool = False\n",
    "\n",
    "    def setup(self):\n",
    "        self.seq = self.layer_cls(**self.layer, decode=self.decode)\n",
    "        self.norm = nn.LayerNorm()\n",
    "        self.out = nn.Dense(self.d_model)\n",
    "        if self.glu:\n",
    "            self.out2 = nn.Dense(self.d_model)\n",
    "        self.drop = nn.Dropout(\n",
    "            self.dropout,\n",
    "            broadcast_dims=[0],\n",
    "            deterministic=not self.training,\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        skip = x\n",
    "        if self.prenorm:\n",
    "            x = self.norm(x)\n",
    "        x = self.seq(x)\n",
    "        x = self.drop(nn.gelu(x))\n",
    "        if self.glu:\n",
    "            x = self.out(x) * jax.nn.sigmoid(self.out2(x))\n",
    "        else:\n",
    "            x = self.out(x)\n",
    "        x = skip + self.drop(x)\n",
    "        if not self.prenorm:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def cloneLayer(layer):\n",
    "    \"\"\"\n",
    "    This will create 'embed dimension' number of copies of params A, B, C, step (D is just 1 in this case)\n",
    "    Each embed dimension is treated as its own 1D sequence with its own A, B, C, step.\n",
    "\n",
    "    For example sequence of length 3 with embed dim 2 would look like\n",
    "    np.array([\n",
    "        [1, 2, 3], \n",
    "        [2, 6, 10],\n",
    "        [3, 7, 11],\n",
    "    ])\n",
    "\n",
    "    This is 3 independent sequences of length 3: [1, 2, 3], [2, 6, 10], [3, 7, 11]\n",
    "    \"\"\"\n",
    "    return nn.vmap(\n",
    "        layer,\n",
    "        in_axes=1,\n",
    "        out_axes=1,\n",
    "        variable_axes={\"params\": 1, \"cache\": 1, \"prime\": 1},\n",
    "        split_rngs={\"params\": True},\n",
    "    )\n",
    "\n",
    "\n",
    "class Embedding(nn.Embed):\n",
    "    num_embeddings: int # size of vocab\n",
    "    features: int # embed dimension\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        y = nn.Embed(num_embeddings=self.num_embeddings, features=self.features)(x[..., 0])\n",
    "        return np.where(x > 0, y, 0.0)\n",
    "\n",
    "\n",
    "class StackedModel(nn.Module):\n",
    "    layer_cls: nn.Module\n",
    "    layer: dict  # Extra arguments to pass into layer constructor\n",
    "    d_output: int\n",
    "    d_model: int\n",
    "    n_layers: int\n",
    "    prenorm: bool = True\n",
    "    dropout: float = 0.0\n",
    "    embedding: bool = False  # Use nn.Embed instead of nn.Dense encoder\n",
    "    classification: bool = False\n",
    "    training: bool = True\n",
    "    decode: bool = False  # Probably should be moved into layer_args\n",
    "\n",
    "    def setup(self):\n",
    "        if self.embedding:\n",
    "            self.encoder = Embedding(self.d_output, self.d_model)\n",
    "        else:\n",
    "            self.encoder = nn.Dense(self.d_model)\n",
    "        self.decoder = nn.Dense(self.d_output)\n",
    "        self.layers = [\n",
    "            SequenceBlock(\n",
    "                layer_cls=self.layer_cls,\n",
    "                layer=self.layer,\n",
    "                prenorm=self.prenorm,\n",
    "                d_model=self.d_model,\n",
    "                dropout=self.dropout,\n",
    "                training=self.training,\n",
    "                decode=self.decode,\n",
    "            )\n",
    "            for _ in range(self.n_layers)\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not self.classification:\n",
    "            if not self.embedding:\n",
    "                x = x / 255.0  # Normalize\n",
    "            if not self.decode:\n",
    "                x = np.pad(x[:-1], [(1, 0), (0, 0)])\n",
    "        x = self.encoder(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        if self.classification:\n",
    "            x = np.mean(x, axis=0)\n",
    "        x = self.decoder(x)\n",
    "        return nn.log_softmax(x, axis=-1)\n",
    "    \n",
    "BatchStackedModel = nn.vmap(\n",
    "    StackedModel,\n",
    "    in_axes=0,\n",
    "    out_axes=0,\n",
    "    variable_axes={\"params\": None, \"dropout\": None, \"cache\": 0, \"prime\": None},\n",
    "    # seet both to false means batch of two input sequences give identical outputs \n",
    "    split_rngs={\"params\": False, \"dropout\": True},\n",
    ")\n",
    "\n",
    "\n",
    "def make_HiPPO(N):\n",
    "    P = np.sqrt(1 + 2 * np.arange(N))\n",
    "    A = P[:, np.newaxis] * P[np.newaxis, :]\n",
    "    A = np.tril(A) - np.diag(np.arange(N))\n",
    "    return -A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hippo Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-1.       , -0.       , -0.       , -0.       , -0.       ],\n",
       "       [-1.7320508, -2.       , -0.       , -0.       , -0.       ],\n",
       "       [-2.236068 , -3.8729832, -3.       , -0.       , -0.       ],\n",
       "       [-2.6457512, -4.5825753, -5.9160795, -3.9999995, -0.       ],\n",
       "       [-3.       , -5.196152 , -6.7082043, -7.937254 , -5.       ]],      dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_HiPPO(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchStackedModel layer init example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (2, 5, 5)\n",
      "Output shape (2, 5, 5)\n",
      "Output: [[[-1.609438  -1.609438  -1.609438  -1.609438  -1.609438 ]\n",
      "  [-2.3469849 -1.6016883 -1.0093875 -2.2912683 -1.4388237]\n",
      "  [-2.3390398 -1.6000339 -1.0143468 -2.27979   -1.4407709]\n",
      "  [-2.3321614 -1.598366  -1.0187337 -2.2694275 -1.4428031]\n",
      "  [-2.3263168 -1.5966854 -1.0225577 -2.2601302 -1.4449086]]\n",
      "\n",
      " [[-1.609438  -1.609438  -1.609438  -1.609438  -1.609438 ]\n",
      "  [-2.3469849 -1.6016883 -1.0093875 -2.2912683 -1.4388237]\n",
      "  [-2.3390398 -1.6000339 -1.0143468 -2.27979   -1.4407709]\n",
      "  [-2.3321614 -1.598366  -1.0187337 -2.2694275 -1.4428031]\n",
      "  [-2.3263168 -1.5966854 -1.0225577 -2.2601302 -1.4449086]]]\n",
      "\n",
      "\u001b[3m                            VmapStackedModel Summary                            \u001b[0m\n",
      "ââââââââââââââ³âââââââââââââ³âââââââââââââ³âââââââââââââ³âââââââââââââ³ââââââââââââââ\n",
      "â\u001b[1m \u001b[0m\u001b[1mpath      \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mmodule    \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1minputs    \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1moutputs   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mparams    \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mcache      \u001b[0m\u001b[1m \u001b[0mâ\n",
      "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
      "â            â VmapStackâ¦ â \u001b[2mint32\u001b[0m[]    â \u001b[2mint32\u001b[0m[]    â decoder:   â layers_0:   â\n",
      "â            â            â            â            â   bias:    â   seq:      â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[5] â     cache_â¦ â\n",
      "â            â            â            â            â   kernel:  â \u001b[2mfloat32\u001b[0m[2,â¦ â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4â¦ â layers_1:   â\n",
      "â            â            â            â            â encoder:   â   seq:      â\n",
      "â            â            â            â            â   bias:    â     cache_â¦ â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â \u001b[2mfloat32\u001b[0m[2,â¦ â\n",
      "â            â            â            â            â   kernel:  â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[1m96 \u001b[0m\u001b[1;2m(384 B)\u001b[0m  â\n",
      "â            â            â            â            â layers_0:  â             â\n",
      "â            â            â            â            â   norm:    â             â\n",
      "â            â            â            â            â     bias:  â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â     scale: â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â   out:     â             â\n",
      "â            â            â            â            â     bias:  â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â     kerneâ¦ â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4â¦ â             â\n",
      "â            â            â            â            â   out2:    â             â\n",
      "â            â            â            â            â     bias:  â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â     kerneâ¦ â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4â¦ â             â\n",
      "â            â            â            â            â   seq:     â             â\n",
      "â            â            â            â            â     A:     â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[6â¦ â             â\n",
      "â            â            â            â            â     B:     â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[6â¦ â             â\n",
      "â            â            â            â            â     C:     â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â     D:     â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â     log_sâ¦ â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â layers_1:  â             â\n",
      "â            â            â            â            â   norm:    â             â\n",
      "â            â            â            â            â     bias:  â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â     scale: â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â   out:     â             â\n",
      "â            â            â            â            â     bias:  â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â     kerneâ¦ â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4â¦ â             â\n",
      "â            â            â            â            â   out2:    â             â\n",
      "â            â            â            â            â     bias:  â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â     kerneâ¦ â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4â¦ â             â\n",
      "â            â            â            â            â   seq:     â             â\n",
      "â            â            â            â            â     A:     â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[6â¦ â             â\n",
      "â            â            â            â            â     B:     â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[6â¦ â             â\n",
      "â            â            â            â            â     C:     â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â     D:     â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â     log_sâ¦ â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â            â             â\n",
      "â            â            â            â            â \u001b[1m545 \u001b[0m\u001b[1;2m(2.2 \u001b[0m  â             â\n",
      "â            â            â            â            â \u001b[1;2mKB)\u001b[0m        â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â            â StackedMoâ¦ â \u001b[2mint32\u001b[0m[5,5] â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /encoder   â Dense      â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_0  â SequenceBâ¦ â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_0â¦ â LayerNorm  â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_0â¦ â SSMLayer   â \u001b[2mfloat32\u001b[0m[5] â \u001b[2mfloat32\u001b[0m[5] â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_0â¦ â Dropout    â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_0â¦ â Dense      â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_0â¦ â Dense      â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_1  â SequenceBâ¦ â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_1â¦ â LayerNorm  â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_1â¦ â SSMLayer   â \u001b[2mfloat32\u001b[0m[5] â \u001b[2mfloat32\u001b[0m[5] â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_1â¦ â Dropout    â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_1â¦ â Dense      â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /layers_1â¦ â Dense      â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â /decoder   â Dense      â \u001b[2mfloat32\u001b[0m[5â¦ â \u001b[2mfloat32\u001b[0m[5â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m     Total\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m545 \u001b[0m\u001b[1;2m(2.2 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m96 \u001b[0m\u001b[1;2m(384 B)\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0mâ\n",
      "â\u001b[1m            \u001b[0mâ\u001b[1m            \u001b[0mâ\u001b[1m            \u001b[0mâ\u001b[1m            \u001b[0mâ\u001b[1m \u001b[0m\u001b[1;2mKB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m             \u001b[0mâ\n",
      "ââââââââââââââ´âââââââââââââ´âââââââââââââ´âââââââââââââ´âââââââââââââ´ââââââââââââââ\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                         Total Parameters: 641 \u001b[0m\u001b[1;2m(2.6 KB)\u001b[0m\u001b[1m                         \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init_rng, dropout_rng = jax.random.split(rng, num=2)\n",
    "\n",
    "SSMVmap = cloneLayer(SSMLayer)\n",
    "\n",
    "stack = BatchStackedModel(\n",
    "    layer_cls=SSMVmap,\n",
    "    layer={\"N\": 6, \"l_max\": 5},\n",
    "    dropout=0.1,\n",
    "    d_model=4,\n",
    "    d_output=5,\n",
    "    n_layers=2,\n",
    "    decode=False # if False requires dim of K is same length as input seq, i.e l_max = seq length\n",
    ")\n",
    "\n",
    "# A batch of two sequences of embeddings\n",
    "# ncols, embed dim = d_model, nrows = seq length\n",
    "x = np.array([\n",
    "    # seq 1\n",
    "    [[1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5]],\n",
    "    # seq 2 \n",
    "    [[1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5]],\n",
    "])\n",
    "\n",
    "o, p = stack.init_with_output({\"params\": init_rng, \"dropout\": dropout_rng}, x)\n",
    "\n",
    "print(\"Input shape\", x.shape)\n",
    "print(\"Output shape\", o.shape)\n",
    "print(\"Output:\", o)\n",
    "tabulate_fn = nn.tabulate(stack, {\"params\": init_rng, \"dropout\": dropout_rng})\n",
    "print(tabulate_fn(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackedModel layer init example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (4, 5)\n",
      "Output shape (4, 5)\n",
      "Output: [[-2.3469849 -1.6016883 -1.0093875 -2.2912683 -1.4388237]\n",
      " [-2.3390398 -1.6000339 -1.0143468 -2.27979   -1.4407709]\n",
      " [-2.3321614 -1.598366  -1.0187337 -2.2694275 -1.4428031]\n",
      " [-2.3263168 -1.5966854 -1.0225577 -2.2601302 -1.4449086]]\n",
      "\n",
      "\u001b[3m                              StackedModel Summary                              \u001b[0m\n",
      "ââââââââââââââ³âââââââââââââ³âââââââââââââ³âââââââââââââ³âââââââââââââ³ââââââââââââââ\n",
      "â\u001b[1m \u001b[0m\u001b[1mpath      \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mmodule    \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1minputs    \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1moutputs   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mparams    \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mcache      \u001b[0m\u001b[1m \u001b[0mâ\n",
      "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
      "â            â StackedMoâ¦ â \u001b[2mint32\u001b[0m[4,5] â \u001b[2mfloat32\u001b[0m[4â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â encoder    â Dense      â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â bias:      â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â kernel:    â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[5â¦ â             â\n",
      "â            â            â            â            â            â             â\n",
      "â            â            â            â            â \u001b[1m24 \u001b[0m\u001b[1;2m(96 B)\u001b[0m  â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_0   â SequenceBâ¦ â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_0/â¦ â LayerNorm  â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â bias:      â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â scale:     â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â            â             â\n",
      "â            â            â            â            â \u001b[1m8 \u001b[0m\u001b[1;2m(32 B)\u001b[0m   â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_0/â¦ â SSMLayer   â \u001b[2mfloat32\u001b[0m[4] â \u001b[2mfloat32\u001b[0m[4] â A:         â cache_x_k:  â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[6â¦ â \u001b[2mfloat32\u001b[0m[6,â¦ â\n",
      "â            â            â            â            â B:         â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[6â¦ â \u001b[1m24 \u001b[0m\u001b[1;2m(96 B)\u001b[0m   â\n",
      "â            â            â            â            â C:         â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â D:         â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â log_step:  â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â            â             â\n",
      "â            â            â            â            â \u001b[1m200 \u001b[0m\u001b[1;2m(800 \u001b[0m  â             â\n",
      "â            â            â            â            â \u001b[1;2mB)\u001b[0m         â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_0/â¦ â Dropout    â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_0/â¦ â Dense      â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â bias:      â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â kernel:    â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4â¦ â             â\n",
      "â            â            â            â            â            â             â\n",
      "â            â            â            â            â \u001b[1m20 \u001b[0m\u001b[1;2m(80 B)\u001b[0m  â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_0/â¦ â Dense      â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â bias:      â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â kernel:    â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4â¦ â             â\n",
      "â            â            â            â            â            â             â\n",
      "â            â            â            â            â \u001b[1m20 \u001b[0m\u001b[1;2m(80 B)\u001b[0m  â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_1   â SequenceBâ¦ â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_1/â¦ â LayerNorm  â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â bias:      â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â scale:     â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â            â             â\n",
      "â            â            â            â            â \u001b[1m8 \u001b[0m\u001b[1;2m(32 B)\u001b[0m   â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_1/â¦ â SSMLayer   â \u001b[2mfloat32\u001b[0m[4] â \u001b[2mfloat32\u001b[0m[4] â A:         â cache_x_k:  â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[6â¦ â \u001b[2mfloat32\u001b[0m[6,â¦ â\n",
      "â            â            â            â            â B:         â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[6â¦ â \u001b[1m24 \u001b[0m\u001b[1;2m(96 B)\u001b[0m   â\n",
      "â            â            â            â            â C:         â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â D:         â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â log_step:  â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[1â¦ â             â\n",
      "â            â            â            â            â            â             â\n",
      "â            â            â            â            â \u001b[1m200 \u001b[0m\u001b[1;2m(800 \u001b[0m  â             â\n",
      "â            â            â            â            â \u001b[1;2mB)\u001b[0m         â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_1/â¦ â Dropout    â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â            â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_1/â¦ â Dense      â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â bias:      â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â kernel:    â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4â¦ â             â\n",
      "â            â            â            â            â            â             â\n",
      "â            â            â            â            â \u001b[1m20 \u001b[0m\u001b[1;2m(80 B)\u001b[0m  â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â layers_1/â¦ â Dense      â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â bias:      â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4] â             â\n",
      "â            â            â            â            â kernel:    â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4â¦ â             â\n",
      "â            â            â            â            â            â             â\n",
      "â            â            â            â            â \u001b[1m20 \u001b[0m\u001b[1;2m(80 B)\u001b[0m  â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â decoder    â Dense      â \u001b[2mfloat32\u001b[0m[4â¦ â \u001b[2mfloat32\u001b[0m[4â¦ â bias:      â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[5] â             â\n",
      "â            â            â            â            â kernel:    â             â\n",
      "â            â            â            â            â \u001b[2mfloat32\u001b[0m[4â¦ â             â\n",
      "â            â            â            â            â            â             â\n",
      "â            â            â            â            â \u001b[1m25 \u001b[0m\u001b[1;2m(100 B)\u001b[0m â             â\n",
      "ââââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼âââââââââââââ¼ââââââââââââââ¤\n",
      "â\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m     Total\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m545 \u001b[0m\u001b[1;2m(2.2 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m48 \u001b[0m\u001b[1;2m(192 B)\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0mâ\n",
      "â\u001b[1m            \u001b[0mâ\u001b[1m            \u001b[0mâ\u001b[1m            \u001b[0mâ\u001b[1m            \u001b[0mâ\u001b[1m \u001b[0m\u001b[1;2mKB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m             \u001b[0mâ\n",
      "ââââââââââââââ´âââââââââââââ´âââââââââââââ´âââââââââââââ´âââââââââââââ´ââââââââââââââ\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                         Total Parameters: 593 \u001b[0m\u001b[1;2m(2.4 KB)\u001b[0m\u001b[1m                         \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init_rng, dropout_rng = jax.random.split(rng, num=2)\n",
    "\n",
    "SSMVmap = cloneLayer(SSMLayer)\n",
    "\n",
    "stack = StackedModel(\n",
    "    layer_cls=SSMVmap,\n",
    "    layer={\"N\": 6, \"l_max\": 5},\n",
    "    dropout=0.1,\n",
    "    d_model=4,\n",
    "    d_output=5,\n",
    "    n_layers=2,\n",
    "    decode=True\n",
    ")\n",
    "\n",
    "# A single sequence of embeddings\n",
    "# ncols, embed dim = d_model, nrows = seq length\n",
    "x = np.array([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "])\n",
    "\n",
    "o, p = stack.init_with_output({\"params\": init_rng, \"dropout\": dropout_rng}, x)\n",
    "\n",
    "print(\"Input shape\", x.shape)\n",
    "print(\"Output shape\", o.shape)\n",
    "print(\"Output:\", o)\n",
    "tabulate_fn = nn.tabulate(stack, {\"params\": init_rng, \"dropout\": dropout_rng})\n",
    "print(tabulate_fn(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed layer init example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'embedding': Array([[-0.5474848 , -0.48036295,  0.10160114],\n",
      "       [ 0.5684244 , -0.3826952 , -0.9501267 ],\n",
      "       [-0.7158868 , -0.3815823 , -0.03696465],\n",
      "       [ 0.32678705,  0.9207937 , -0.5220883 ],\n",
      "       [-0.22882082, -0.6123475 , -0.67258674]], dtype=float32), 'Embed_0': {'embedding': Array([[-0.5431886 ,  0.223633  , -1.0188975 ],\n",
      "       [ 0.9756091 , -0.47169256,  0.10822168],\n",
      "       [-0.37928337,  0.5580153 , -0.26732865],\n",
      "       [-0.63215506,  0.37527135, -0.26105613],\n",
      "       [ 0.5191519 , -0.51038426,  0.08034096]], dtype=float32)}}}\n",
      "[[        nan         nan         nan]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.9756091  -0.47169256  0.10822168]\n",
      " [-0.37928337  0.5580153  -0.26732865]\n",
      " [ 0.          0.          0.        ]\n",
      " [-0.63215506  0.37527135 -0.26105613]]\n"
     ]
    }
   ],
   "source": [
    "layer = Embedding(num_embeddings=5, features=3)\n",
    "indices_input = np.array([[6],  [0], [1], [2], [-1], [3]])\n",
    "output, params = layer.init_with_output(jax.random.PRNGKey(1), indices_input)\n",
    "\n",
    "print(params)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Embed module example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'embedding': Array([[-0.5474848 , -0.48036295,  0.10160114],\n",
       "         [ 0.5684244 , -0.3826952 , -0.9501267 ],\n",
       "         [-0.7158868 , -0.3815823 , -0.03696465],\n",
       "         [ 0.32678705,  0.9207937 , -0.5220883 ],\n",
       "         [-0.22882082, -0.6123475 , -0.67258674]], dtype=float32)}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flax.linen as nn\n",
    "import jax, jax.numpy as jnp\n",
    "\n",
    "layer = nn.Embed(num_embeddings=5, features=3)\n",
    "indices_input = jnp.array([[0], [-1]])\n",
    "variables = layer.init(jax.random.PRNGKey(1), indices_input)\n",
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq block Layer init example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (5, 4)\n",
      "Output shape (5, 4)\n",
      "\n",
      "\u001b[3m                             SequenceBlock Summary                              \u001b[0m\n",
      "ââââââââ³ââââââââââââââ³âââââââââââââââ³ââââââââââââââ³âââââââââââââââ³ââââââââââââââ\n",
      "â\u001b[1m \u001b[0m\u001b[1mpath\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mmodule     \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1moutputs    \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mparams      \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mcache      \u001b[0m\u001b[1m \u001b[0mâ\n",
      "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
      "â      â SequenceBlâ¦ â \u001b[2mint32\u001b[0m[5,4]   â \u001b[2mfloat32\u001b[0m[5,â¦ â              â             â\n",
      "ââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¤\n",
      "â norm â LayerNorm   â \u001b[2mint32\u001b[0m[5,4]   â \u001b[2mfloat32\u001b[0m[5,â¦ â bias:        â             â\n",
      "â      â             â              â             â \u001b[2mfloat32\u001b[0m[4]   â             â\n",
      "â      â             â              â             â scale:       â             â\n",
      "â      â             â              â             â \u001b[2mfloat32\u001b[0m[4]   â             â\n",
      "â      â             â              â             â              â             â\n",
      "â      â             â              â             â \u001b[1m8 \u001b[0m\u001b[1;2m(32 B)\u001b[0m     â             â\n",
      "ââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¤\n",
      "â seq  â SSMLayer    â \u001b[2mfloat32\u001b[0m[5]   â \u001b[2mfloat32\u001b[0m[5]  â A:           â cache_x_k:  â\n",
      "â      â             â              â             â \u001b[2mfloat32\u001b[0m[6,4â¦ â \u001b[2mfloat32\u001b[0m[6,â¦ â\n",
      "â      â             â              â             â B:           â             â\n",
      "â      â             â              â             â \u001b[2mfloat32\u001b[0m[6,4â¦ â \u001b[1m24 \u001b[0m\u001b[1;2m(96 B)\u001b[0m   â\n",
      "â      â             â              â             â C:           â             â\n",
      "â      â             â              â             â \u001b[2mfloat32\u001b[0m[1,4â¦ â             â\n",
      "â      â             â              â             â D:           â             â\n",
      "â      â             â              â             â \u001b[2mfloat32\u001b[0m[1,4] â             â\n",
      "â      â             â              â             â log_step:    â             â\n",
      "â      â             â              â             â \u001b[2mfloat32\u001b[0m[1,4] â             â\n",
      "â      â             â              â             â              â             â\n",
      "â      â             â              â             â \u001b[1m200 \u001b[0m\u001b[1;2m(800 B)\u001b[0m  â             â\n",
      "ââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¤\n",
      "â drop â Dropout     â \u001b[2mfloat32\u001b[0m[5,4] â \u001b[2mfloat32\u001b[0m[5,â¦ â              â             â\n",
      "ââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¤\n",
      "â out  â Dense       â \u001b[2mfloat32\u001b[0m[5,4] â \u001b[2mfloat32\u001b[0m[5,â¦ â bias:        â             â\n",
      "â      â             â              â             â \u001b[2mfloat32\u001b[0m[4]   â             â\n",
      "â      â             â              â             â kernel:      â             â\n",
      "â      â             â              â             â \u001b[2mfloat32\u001b[0m[4,4] â             â\n",
      "â      â             â              â             â              â             â\n",
      "â      â             â              â             â \u001b[1m20 \u001b[0m\u001b[1;2m(80 B)\u001b[0m    â             â\n",
      "ââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¤\n",
      "â out2 â Dense       â \u001b[2mfloat32\u001b[0m[5,4] â \u001b[2mfloat32\u001b[0m[5,â¦ â bias:        â             â\n",
      "â      â             â              â             â \u001b[2mfloat32\u001b[0m[4]   â             â\n",
      "â      â             â              â             â kernel:      â             â\n",
      "â      â             â              â             â \u001b[2mfloat32\u001b[0m[4,4] â             â\n",
      "â      â             â              â             â              â             â\n",
      "â      â             â              â             â \u001b[1m20 \u001b[0m\u001b[1;2m(80 B)\u001b[0m    â             â\n",
      "ââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¼âââââââââââââââ¼ââââââââââââââ¤\n",
      "â\u001b[1m \u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m      Total\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m248 \u001b[0m\u001b[1;2m(992 B)\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m24 \u001b[0m\u001b[1;2m(96 B)\u001b[0m\u001b[1m  \u001b[0m\u001b[1m \u001b[0mâ\n",
      "ââââââââ´ââââââââââââââ´âââââââââââââââ´ââââââââââââââ´âââââââââââââââ´ââââââââââââââ\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                         Total Parameters: 272 \u001b[0m\u001b[1;2m(1.1 KB)\u001b[0m\u001b[1m                         \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init_rng, dropout_rng = jax.random.split(rng, num=2)\n",
    "SSMVmap = cloneLayer(SSMLayer)\n",
    "\n",
    "# d_model, must match embedding dimenstion for (skip + x) to work.  (L * embed dim) + (L * d_model)\n",
    "seq = SequenceBlock(\n",
    "    layer_cls=SSMVmap,\n",
    "    layer={\"N\": 6, \"l_max\": 5},\n",
    "    dropout=0.1,\n",
    "    d_model=4,\n",
    "    decode=False\n",
    "    # training=False\n",
    ")\n",
    "\n",
    "# A single sequence of embeddings\n",
    "# ncols, embed dim = d_model, nrows = seq length\n",
    "x = np.array([\n",
    "    [1, 2, 3,  10], \n",
    "    [2, 6, 10, 10],\n",
    "    [3, 7, 11, 10],\n",
    "    [4, 7, 11, 10],\n",
    "    [4, 7, 10, 11]\n",
    "])\n",
    "\n",
    "o, p = seq.init_with_output({\"params\": init_rng, \"dropout\": dropout_rng}, x)\n",
    "\n",
    "print(\"Input shape\", x.shape)\n",
    "print(\"Output shape\", o.shape)\n",
    "tabulate_fn = nn.tabulate(seq, {\"params\": init_rng, \"dropout\": dropout_rng})\n",
    "print(tabulate_fn(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSM Layer init example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "[1.0578151 2.175106  3.3536835 4.59551   5.9027014]\n",
      "[[ 0.9848459  1.9725535  2.9852316]\n",
      " [ 1.954891   5.8906164  9.936184 ]\n",
      " [ 2.9104915  6.7961617 10.882811 ]\n",
      " [ 3.8520064  6.7031116 10.830082 ]\n",
      " [ 3.7949517  6.611464  10.777983 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felix/Documents/learning/annotated_s4/venv/lib/python3.8/site-packages/flax/core/lift.py:137: RuntimeWarning: kwargs are not supported in vmap, so \"compute_flops, compute_vjp_flops\" is(are) ignored\n",
      "  warnings.warn(msg.format(name, ', '.join(kwargs.keys())), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                              VmapSSMLayer Summary                              \u001b[0m\n",
      "ââââââââ³âââââââââââââââ³âââââââââââ³âââââââââââââ³âââââââââââââââââ³ââââââââââââââââ\n",
      "â\u001b[1m \u001b[0m\u001b[1mpath\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mmodule      \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1minputs  \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1moutputs   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mparams        \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mcache        \u001b[0m\u001b[1m \u001b[0mâ\n",
      "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
      "â      â VmapSSMLayer â \u001b[2mint32\u001b[0m[]  â \u001b[2mint32\u001b[0m[]    â A:             â cache_x_k:    â\n",
      "â      â              â          â            â \u001b[2mfloat32\u001b[0m[12,3,â¦ â \u001b[2mfloat32\u001b[0m[12,3] â\n",
      "â      â              â          â            â B:             â               â\n",
      "â      â              â          â            â \u001b[2mfloat32\u001b[0m[12,3,â¦ â \u001b[1m36 \u001b[0m\u001b[1;2m(144 B)\u001b[0m    â\n",
      "â      â              â          â            â C:             â               â\n",
      "â      â              â          â            â \u001b[2mfloat32\u001b[0m[1,3,1â¦ â               â\n",
      "â      â              â          â            â D:             â               â\n",
      "â      â              â          â            â \u001b[2mfloat32\u001b[0m[1,3]   â               â\n",
      "â      â              â          â            â log_step:      â               â\n",
      "â      â              â          â            â \u001b[2mfloat32\u001b[0m[1,3]   â               â\n",
      "â      â              â          â            â                â               â\n",
      "â      â              â          â            â \u001b[1m510 \u001b[0m\u001b[1;2m(2.0 KB)\u001b[0m   â               â\n",
      "ââââââââ¼âââââââââââââââ¼âââââââââââ¼âââââââââââââ¼âââââââââââââââââ¼ââââââââââââââââ¤\n",
      "â      â SSMLayer     â \u001b[2mint32\u001b[0m[5] â \u001b[2mfloat32\u001b[0m[5] â                â               â\n",
      "ââââââââ¼âââââââââââââââ¼âââââââââââ¼âââââââââââââ¼âââââââââââââââââ¼ââââââââââââââââ¤\n",
      "â\u001b[1m \u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m     Total\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m510 \u001b[0m\u001b[1;2m(2.0 KB)\u001b[0m\u001b[1m  \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m36 \u001b[0m\u001b[1;2m(144 B)\u001b[0m\u001b[1m   \u001b[0m\u001b[1m \u001b[0mâ\n",
      "ââââââââ´âââââââââââââââ´âââââââââââ´âââââââââââââ´âââââââââââââââââ´ââââââââââââââââ\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                         Total Parameters: 546 \u001b[0m\u001b[1;2m(2.2 KB)\u001b[0m\u001b[1m                         \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SSMVmap = cloneLayer(SSMLayer)\n",
    "\n",
    "\n",
    "# Dim of K is l_max x l_max, for decode=False need u.shape[0] == K.shape[0] == l_max\n",
    "s1 = SSMLayer(N=12, l_max=5, decode=False)\n",
    "s2 = SSMVmap(N=12, l_max=5, decode=False)\n",
    "\n",
    "# Init done WITH dummy input data for shape inference\n",
    "# Basic 1D version\n",
    "x1 = np.array(\n",
    "    [1, 2, 3, 4, 5]\n",
    ")\n",
    "o1, p1 = s1.init_with_output(jax.random.PRNGKey(1), x1)\n",
    "\n",
    "# V mapped verison\n",
    "# ncols, embed dim = d_model, nrows = seq length\n",
    "x2 = np.array([\n",
    "    [1, 2, 3], \n",
    "    [2, 6, 10],\n",
    "    [3, 7, 11],\n",
    "    [4, 7, 11],\n",
    "    [4, 7, 11]\n",
    "])\n",
    "o2, p2 = s2.init_with_output(jax.random.PRNGKey(1), x2)\n",
    "print(\"----\")\n",
    "print(s1.apply(p1, x1))\n",
    "print(s2.apply(p2, x2))\n",
    "\n",
    "tabulate_fn = nn.tabulate(SSMVmap(N=12, l_max=5, decode=False), jax.random.PRNGKey(1), compute_flops=True, compute_vjp_flops=True)\n",
    "print(tabulate_fn(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple vmap example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 9]\n",
      "[5 7 9]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "vmap was requested to map its argument along axis 2, which implies that its rank should be at least 3, but is only 2 (its shape is (2, 3))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/learning/annotated_s4/venv/lib/python3.8/site-packages/jax/_src/api.py:1260\u001b[0m, in \u001b[0;36m_mapped_axis_size.<locals>._get_axis_size\u001b[0;34m(name, shape, axis)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]]), np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]]):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(func(x, y))\n\u001b[0;32m---> 12\u001b[0m \u001b[43mfunc_vmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/learning/annotated_s4/venv/lib/python3.8/site-packages/jax/_src/api.py:1264\u001b[0m, in \u001b[0;36m_mapped_axis_size.<locals>._get_axis_size\u001b[0;34m(name, shape, axis)\u001b[0m\n\u001b[1;32m   1262\u001b[0m min_rank \u001b[38;5;241m=\u001b[39m axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39maxis\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;66;03m# TODO(mattjj): better error message here\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was requested to map its argument along axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich implies that its rank should be at least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_rank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut is only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (its shape is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: vmap was requested to map its argument along axis 2, which implies that its rank should be at least 3, but is only 2 (its shape is (2, 3))"
     ]
    }
   ],
   "source": [
    "def func(x, y):\n",
    "    return x + y\n",
    "\n",
    "func_vmap =jax.vmap(\n",
    "    func\n",
    "    , in_axes=1, out_axes=1\n",
    ")\n",
    "\n",
    "for x, y in np.array([[1, 2, 3], [4, 5, 6]]), np.array([[1,2,3], [4, 5, 6]]):\n",
    "    print(func(x, y))\n",
    "\n",
    "func_vmap(np.array([[1, 2, 3], [4, 5, 6]]), np.array([[1,2,3], [4, 5, 6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanics example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0. 0.]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0. 0.]\n",
      "y_k = Cb @ x_k: [0.]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0. 0.]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0. 0.]\n",
      "y_k = Cb @ x_k: [0.]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0. 0.]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0. 0.]\n",
      "y_k = Cb @ x_k: [0.]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0. 0.]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0. 0.]\n",
      "y_k = Cb @ x_k: [0.]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0. 0.]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0. 0.]\n",
      "y_k = Cb @ x_k: [0.]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0. 0.]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0. 0.]\n",
      "y_k = Cb @ x_k: [0.]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0. 0.]\n",
      "u_k: [0.5646424]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [2.7516684e-05 5.5033369e-03]\n",
      "y_k = Cb @ x_k: [2.7516684e-05]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [2.7516684e-05 5.5033369e-03]\n",
      "u_k: [0.64421767]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.0001125  0.01149261]\n",
      "y_k = Cb @ x_k: [0.0001125]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.0001125  0.01149261]\n",
      "u_k: [0.7173561]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00025925 0.01785806]\n",
      "y_k = Cb @ x_k: [0.00025925]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00025925 0.01785806]\n",
      "u_k: [0.7833269]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00047097 0.02448666]\n",
      "y_k = Cb @ x_k: [0.00047097]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00047097 0.02448666]\n",
      "u_k: [0.84147096]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00074972 0.03126348]\n",
      "y_k = Cb @ x_k: [0.00074972]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00074972 0.03126348]\n",
      "u_k: [0.8912074]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00109641 0.03807291]\n",
      "y_k = Cb @ x_k: [0.00109641]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00109641 0.03807291]\n",
      "u_k: [0.9320391]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00151077 0.04480005]\n",
      "y_k = Cb @ x_k: [0.00151077]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00151077 0.04480005]\n",
      "u_k: [0.9635582]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00199143 0.05133189]\n",
      "y_k = Cb @ x_k: [0.00199143]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00199143 0.05133189]\n",
      "u_k: [0.98544973]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00253588 0.05755866]\n",
      "y_k = Cb @ x_k: [0.00253588]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00253588 0.05755866]\n",
      "u_k: [0.997495]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00314055 0.06337498]\n",
      "y_k = Cb @ x_k: [0.00314055]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00314055 0.06337498]\n",
      "u_k: [0.9995736]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00380083 0.06868104]\n",
      "y_k = Cb @ x_k: [0.00380083]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00380083 0.06868104]\n",
      "u_k: [0.9916648]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00451116 0.07338367]\n",
      "y_k = Cb @ x_k: [0.00451116]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00451116 0.07338367]\n",
      "u_k: [0.9738476]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00526506 0.07739738]\n",
      "y_k = Cb @ x_k: [0.00526506]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00526506 0.07739738]\n",
      "u_k: [0.9463001]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00605527 0.08064525]\n",
      "y_k = Cb @ x_k: [0.00605527]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00605527 0.08064525]\n",
      "u_k: [0.90929747]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.0068738  0.08305978]\n",
      "y_k = Cb @ x_k: [0.0068738]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.0068738  0.08305978]\n",
      "u_k: [0.8632094]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00771202 0.08458363]\n",
      "y_k = Cb @ x_k: [0.00771202]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00771202 0.08458363]\n",
      "u_k: [0.80849636]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00856079 0.08517019]\n",
      "y_k = Cb @ x_k: [0.00856079]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00856079 0.08517019]\n",
      "u_k: [0.74570525]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00941056 0.08478411]\n",
      "y_k = Cb @ x_k: [0.00941056]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00941056 0.08478411]\n",
      "u_k: [0.67546326]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01025149 0.08340169]\n",
      "y_k = Cb @ x_k: [0.01025149]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01025149 0.08340169]\n",
      "u_k: [0.5984721]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01107355 0.08101108]\n",
      "y_k = Cb @ x_k: [0.01107355]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01107355 0.08101108]\n",
      "u_k: [0.51550144]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01186667 0.07761247]\n",
      "y_k = Cb @ x_k: [0.01186667]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01186667 0.07761247]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01259999 0.06905251]\n",
      "y_k = Cb @ x_k: [0.01259999]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01259999 0.06905251]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01324846 0.0606405 ]\n",
      "y_k = Cb @ x_k: [0.01324846]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01324846 0.0606405 ]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01381367 0.05240201]\n",
      "y_k = Cb @ x_k: [0.01381367]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01381367 0.05240201]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01429748 0.04436071]\n",
      "y_k = Cb @ x_k: [0.01429748]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01429748 0.04436071]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01470198 0.03653834]\n",
      "y_k = Cb @ x_k: [0.01470198]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01470198 0.03653834]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01502944 0.02895473]\n",
      "y_k = Cb @ x_k: [0.01502944]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01502944 0.02895473]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01528236 0.02162781]\n",
      "y_k = Cb @ x_k: [0.01528236]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01528236 0.02162781]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01546337 0.01457363]\n",
      "y_k = Cb @ x_k: [0.01546337]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01546337 0.01457363]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01557527 0.0078064 ]\n",
      "y_k = Cb @ x_k: [0.01557527]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01557527 0.0078064 ]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01562099 0.00133853]\n",
      "y_k = Cb @ x_k: [0.01562099]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01562099 0.00133853]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01560359 -0.00481936]\n",
      "y_k = Cb @ x_k: [0.01560359]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01560359 -0.00481936]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.0155262  -0.01065838]\n",
      "y_k = Cb @ x_k: [0.0155262]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.0155262  -0.01065838]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01539205 -0.01617128]\n",
      "y_k = Cb @ x_k: [0.01539205]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01539205 -0.01617128]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01520443 -0.02135248]\n",
      "y_k = Cb @ x_k: [0.01520443]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01520443 -0.02135248]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01496668 -0.02619795]\n",
      "y_k = Cb @ x_k: [0.01496668]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01496668 -0.02619795]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01468216 -0.03070514]\n",
      "y_k = Cb @ x_k: [0.01468216]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01468216 -0.03070514]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01435427 -0.03487297]\n",
      "y_k = Cb @ x_k: [0.01435427]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01435427 -0.03487297]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.0139864  -0.03870174]\n",
      "y_k = Cb @ x_k: [0.0139864]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.0139864  -0.03870174]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01358193 -0.04219304]\n",
      "y_k = Cb @ x_k: [0.01358193]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01358193 -0.04219304]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01314421 -0.04534969]\n",
      "y_k = Cb @ x_k: [0.01314421]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01314421 -0.04534969]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01267658 -0.04817572]\n",
      "y_k = Cb @ x_k: [0.01267658]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01267658 -0.04817572]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01218233 -0.0506762 ]\n",
      "y_k = Cb @ x_k: [0.01218233]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01218233 -0.0506762 ]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01166466 -0.05285726]\n",
      "y_k = Cb @ x_k: [0.01166466]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01166466 -0.05285726]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01112674 -0.05472596]\n",
      "y_k = Cb @ x_k: [0.01112674]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01112674 -0.05472596]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01057166 -0.05629024]\n",
      "y_k = Cb @ x_k: [0.01057166]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01057166 -0.05629024]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.01000242 -0.05755883]\n",
      "y_k = Cb @ x_k: [0.01000242]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.01000242 -0.05755883]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00942191 -0.05854119]\n",
      "y_k = Cb @ x_k: [0.00942191]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00942191 -0.05854119]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00883297 -0.05924746]\n",
      "y_k = Cb @ x_k: [0.00883297]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00883297 -0.05924746]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00823829 -0.05968831]\n",
      "y_k = Cb @ x_k: [0.00823829]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00823829 -0.05968831]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00764048 -0.05987499]\n",
      "y_k = Cb @ x_k: [0.00764048]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00764048 -0.05987499]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00704201 -0.05981913]\n",
      "y_k = Cb @ x_k: [0.00704201]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00704201 -0.05981913]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00644525 -0.05953278]\n",
      "y_k = Cb @ x_k: [0.00644525]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00644525 -0.05953278]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00585244 -0.05902829]\n",
      "y_k = Cb @ x_k: [0.00585244]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00585244 -0.05902829]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00526571 -0.05831826]\n",
      "y_k = Cb @ x_k: [0.00526571]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00526571 -0.05831826]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00468704 -0.05741546]\n",
      "y_k = Cb @ x_k: [0.00468704]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00468704 -0.05741546]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.0041183  -0.05633282]\n",
      "y_k = Cb @ x_k: [0.0041183]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.0041183  -0.05633282]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00356122 -0.05508332]\n",
      "y_k = Cb @ x_k: [0.00356122]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00356122 -0.05508332]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.0030174  -0.05367997]\n",
      "y_k = Cb @ x_k: [0.0030174]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.0030174  -0.05367997]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00248832 -0.05213572]\n",
      "y_k = Cb @ x_k: [0.00248832]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00248832 -0.05213572]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00197533 -0.05046347]\n",
      "y_k = Cb @ x_k: [0.00197533]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00197533 -0.05046347]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00147963 -0.04867597]\n",
      "y_k = Cb @ x_k: [0.00147963]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00147963 -0.04867597]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00100232 -0.04678582]\n",
      "y_k = Cb @ x_k: [0.00100232]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00100232 -0.04678582]\n",
      "u_k: [0.57843983]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.00057255 -0.03916756]\n",
      "y_k = Cb @ x_k: [0.00057255]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.00057255 -0.03916756]\n",
      "u_k: [0.6569866]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [ 0.0002217 -0.0310023]\n",
      "y_k = Cb @ x_k: [0.0002217]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [ 0.0002217 -0.0310023]\n",
      "u_k: [0.728969]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [-4.5370140e-05 -2.2412512e-02]\n",
      "y_k = Cb @ x_k: [-4.537014e-05]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [-4.5370140e-05 -2.2412512e-02]\n",
      "u_k: [0.79366773]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [-0.00022505 -0.01352336]\n",
      "y_k = Cb @ x_k: [-0.00022505]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [-0.00022505 -0.01352336]\n",
      "u_k: [0.85043645]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [-0.00031497 -0.00446137]\n",
      "y_k = Cb @ x_k: [-0.00031497]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [-0.00031497 -0.00446137]\n",
      "u_k: [0.89870816]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [-0.00031405  0.00464688]\n",
      "y_k = Cb @ x_k: [-0.00031405]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [-0.00031405  0.00464688]\n",
      "u_k: [0.93799996]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [-0.00022243  0.0136761 ]\n",
      "y_k = Cb @ x_k: [-0.00022243]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [-0.00022243  0.0136761 ]\n",
      "u_k: [0.96791965]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [-4.1532257e-05  2.2503594e-02]\n",
      "y_k = Cb @ x_k: [-4.1532257e-05]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [-4.1532257e-05  2.2503594e-02]\n",
      "u_k: [0.9881682]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00022604 0.03101052]\n",
      "y_k = Cb @ x_k: [0.00022604]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00022604 0.03101052]\n",
      "u_k: [0.9985433]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00057651 0.0390831 ]\n",
      "y_k = Cb @ x_k: [0.00057651]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00057651 0.0390831 ]\n",
      "u_k: [0.99894136]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00100499 0.0466138 ]\n",
      "y_k = Cb @ x_k: [0.00100499]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00100499 0.0466138 ]\n",
      "u_k: [0.9893583]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00150557 0.05350237]\n",
      "y_k = Cb @ x_k: [0.00150557]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00150557 0.05350237]\n",
      "u_k: [0.9698897]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00207137 0.05965689]\n",
      "y_k = Cb @ x_k: [0.00207137]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00207137 0.05965689]\n",
      "u_k: [0.94073063]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00269463 0.06499471]\n",
      "y_k = Cb @ x_k: [0.00269463]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00269463 0.06499471]\n",
      "u_k: [0.90217173]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00336682 0.06944319]\n",
      "y_k = Cb @ x_k: [0.00336682]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00336682 0.06944319]\n",
      "u_k: [0.8545991]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00407873 0.07294048]\n",
      "y_k = Cb @ x_k: [0.00407873]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00407873 0.07294048]\n",
      "u_k: [0.7984871]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00482062 0.07543607]\n",
      "y_k = Cb @ x_k: [0.00482062]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00482062 0.07543607]\n",
      "u_k: [0.7343975]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00558225 0.07689129]\n",
      "y_k = Cb @ x_k: [0.00558225]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00558225 0.07689129]\n",
      "u_k: [0.66296935]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00635311 0.07727963]\n",
      "y_k = Cb @ x_k: [0.00635311]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00635311 0.07727963]\n",
      "u_k: [0.584917]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00712244 0.07658703]\n",
      "y_k = Cb @ x_k: [0.00712244]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00712244 0.07658703]\n",
      "u_k: [0.5010212]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00787944 0.07481189]\n",
      "y_k = Cb @ x_k: [0.00787944]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00787944 0.07481189]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00859324 0.06794835]\n",
      "y_k = Cb @ x_k: [0.00859324]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00859324 0.06794835]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00923875 0.06115438]\n",
      "y_k = Cb @ x_k: [0.00923875]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00923875 0.06115438]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.00981679 0.05445309]\n",
      "y_k = Cb @ x_k: [0.00981679]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.00981679 0.05445309]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01032838 0.04786608]\n",
      "y_k = Cb @ x_k: [0.01032838]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01032838 0.04786608]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01077478 0.04141346]\n",
      "y_k = Cb @ x_k: [0.01077478]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01077478 0.04141346]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01115742 0.03511383]\n",
      "y_k = Cb @ x_k: [0.01115742]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01115742 0.03511383]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01147791 0.02898432]\n",
      "y_k = Cb @ x_k: [0.01147791]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01147791 0.02898432]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01173803 0.02304051]\n",
      "y_k = Cb @ x_k: [0.01173803]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01173803 0.02304051]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01193972 0.01729653]\n",
      "y_k = Cb @ x_k: [0.01193972]\n",
      "---------\n",
      "Ab: [[ 0.9980507   0.00974659]\n",
      " [-0.38986352  0.94931775]]\n",
      "Bb: [[4.8732938e-05]\n",
      " [9.7465878e-03]]\n",
      "x_k-1: [0.01193972 0.01729653]\n",
      "u_k: [0.]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [0.01208503 0.01176504]\n",
      "y_k = Cb @ x_k: [0.01208503]\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def example_mass(k, b, m):\n",
    "    A = np.array([[0, 1], [-k / m, -b / m]])\n",
    "    B = np.array([[0], [1.0 / m]])\n",
    "    C = np.array([[1.0, 0]])\n",
    "    return A, B, C\n",
    "\n",
    "\n",
    "@partial(np.vectorize, signature=\"()->()\")\n",
    "def example_force(t):\n",
    "    x = np.sin(10 * t)\n",
    "    return x * (x > 0.5)\n",
    "\n",
    "def example_ssm():\n",
    "    # SSM\n",
    "    A, B, C = example_mass(k=40, b=5, m=1)\n",
    "\n",
    "    # L samples of u(t).\n",
    "    L = 100\n",
    "    step = 1.0 / L\n",
    "    ks = np.arange(L)\n",
    "    u = example_force(ks * step)\n",
    "\n",
    "    # Approximation of y(t).\n",
    "    y = run_SSM(A, B, C, u, versbose=True)\n",
    "\n",
    "    # Plotting ---\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn\n",
    "    from celluloid import Camera\n",
    "\n",
    "    seaborn.set_context(\"paper\")\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "    camera = Camera(fig)\n",
    "    ax1.set_title(\"Force $u_k$\")\n",
    "    ax2.set_title(\"Position $y_k$\")\n",
    "    ax3.set_title(\"Object\")\n",
    "    ax1.set_xticks([], [])\n",
    "    ax2.set_xticks([], [])\n",
    "\n",
    "    # Animate plot over time\n",
    "    for k in range(0, L, 2):\n",
    "        ax1.plot(ks[:k], u[:k], color=\"red\")\n",
    "        ax2.plot(ks[:k], y[:k], color=\"blue\")\n",
    "        ax3.boxplot(\n",
    "            [[y[k, 0] - 0.04, y[k, 0], y[k, 0] + 0.04]],\n",
    "            showcaps=False,\n",
    "            whis=False,\n",
    "            vert=False,\n",
    "            widths=10,\n",
    "        )\n",
    "        camera.snap()\n",
    "    anim = camera.animate()\n",
    "    anim.save(\"images/line.gif\", dpi=150, writer=\"imagemagick\")\n",
    "\n",
    "if False:\n",
    "    pass\n",
    "\n",
    "example_ssm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ab: [[1.1005622  0.02939623]\n",
      " [0.01520219 1.0882788 ]]\n",
      "Bb: [[0.05516877 0.0520453 ]\n",
      " [0.08508889 0.08139773]]\n",
      "x_k-1: [[0. 0.]\n",
      " [0. 0.]]\n",
      "u_k: [-0.9859176 -1.0066605]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [[-0.10678381 -0.16583051]\n",
      " [-0.10678381 -0.16583051]]\n",
      "y_k = Cb @ x_k: [[-0.10546135 -0.1637768 ]]\n",
      "---------\n",
      "Ab: [[1.1005622  0.02939623]\n",
      " [0.01520219 1.0882788 ]]\n",
      "Bb: [[0.05516877 0.0520453 ]\n",
      " [0.08508889 0.08139773]]\n",
      "x_k-1: [[-0.10678381 -0.16583051]\n",
      " [-0.10678381 -0.16583051]]\n",
      "u_k: [-0.2213709 -1.3452404]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [[-0.20288746 -0.31571728]\n",
      " [-0.2000601  -0.3113265 ]]\n",
      "y_k = Cb @ x_k: [[-0.198991   -0.30965832]]\n",
      "---------\n",
      "Ab: [[1.1005622  0.02939623]\n",
      " [0.01520219 1.0882788 ]]\n",
      "Bb: [[0.05516877 0.0520453 ]\n",
      " [0.08508889 0.08139773]]\n",
      "x_k-1: [[-0.20288746 -0.31571728]\n",
      " [-0.2000601  -0.3113265 ]]\n",
      "u_k: [ 0.74275523 -2.1406245 ]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [[-0.29960382 -0.46766007]\n",
      " [-0.29123804 -0.4546514 ]]\n",
      "y_k = Cb @ x_k: [[-0.29179892 -0.4555015 ]]\n",
      "---------\n",
      "Ab: [[1.1005622  0.02939623]\n",
      " [0.01520219 1.0882788 ]]\n",
      "Bb: [[0.05516877 0.0520453 ]\n",
      " [0.08508889 0.08139773]]\n",
      "x_k-1: [[-0.29960382 -0.46766007]\n",
      " [-0.29123804 -0.4546514 ]]\n",
      "u_k: [-0.6595632  -0.06608305]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [[-0.37812057 -0.58955455]\n",
      " [-0.3613294  -0.5633974 ]]\n",
      "y_k = Cb @ x_k: [[-0.3652196 -0.5694511]]\n",
      "---------\n",
      "Ab: [[1.1005622  0.02939623]\n",
      " [0.01520219 1.0882788 ]]\n",
      "Bb: [[0.05516877 0.0520453 ]\n",
      " [0.08508889 0.08139773]]\n",
      "x_k-1: [[-0.37812057 -0.58955455]\n",
      " [-0.3613294  -0.5633974 ]]\n",
      "u_k: [-0.21085918 -0.35348117]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [[-0.4567968  -0.71211755]\n",
      " [-0.42900524 -0.6688103 ]]\n",
      "y_k = Cb @ x_k: [[-0.4375375 -0.6821023]]\n",
      "---------\n",
      "Ab: [[1.1005622  0.02939623]\n",
      " [0.01520219 1.0882788 ]]\n",
      "Bb: [[0.05516877 0.0520453 ]\n",
      " [0.08508889 0.08139773]]\n",
      "x_k-1: [[-0.4567968  -0.71211755]\n",
      " [-0.42900524 -0.6688103 ]]\n",
      "u_k: [-1.4126911 -1.9433796]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [[-0.6944246 -1.0817811]\n",
      " [-0.6529018 -1.0170689]]\n",
      "y_k = Cb @ x_k: [[-0.6655019 -1.0367116]]\n",
      "---------\n",
      "Ab: [[1.1005622  0.02939623]\n",
      " [0.01520219 1.0882788 ]]\n",
      "Bb: [[0.05516877 0.0520453 ]\n",
      " [0.08508889 0.08139773]]\n",
      "x_k-1: [[-0.6944246 -1.0817811]\n",
      " [-0.6529018 -1.0170689]]\n",
      "u_k: [1.6297984  0.24093218]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [[-0.680997   -1.0621765 ]\n",
      " [-0.6186426  -0.96501076]]\n",
      "y_k = Cb @ x_k: [[-0.6420449 -1.0014658]]\n",
      "---------\n",
      "Ab: [[1.1005622  0.02939623]\n",
      " [0.01520219 1.0882788 ]]\n",
      "Bb: [[0.05516877 0.0520453 ]\n",
      " [0.08508889 0.08139773]]\n",
      "x_k-1: [[-0.680997   -1.0621765 ]\n",
      " [-0.6186426  -0.96501076]]\n",
      "u_k: [-1.7616359 -0.7132233]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [[-0.90197253 -1.4053094 ]\n",
      " [-0.8179155  -1.2742987 ]]\n",
      "y_k = Cb @ x_k: [[-0.84966177 -1.3237844 ]]\n",
      "---------\n",
      "Ab: [[1.1005622  0.02939623]\n",
      " [0.01520219 1.0882788 ]]\n",
      "Bb: [[0.05516877 0.0520453 ]\n",
      " [0.08508889 0.08139773]]\n",
      "x_k-1: [[-0.90197253 -1.4053094 ]\n",
      " [-0.8179155  -1.2742987 ]]\n",
      "u_k: [ 0.86033255 -0.19197786]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [[-0.9792486  -1.5265119 ]\n",
      " [-0.86636007 -1.3505777 ]]\n",
      "y_k = Cb @ x_k: [[-0.9118697 -1.4214988]]\n",
      "---------\n",
      "Ab: [[1.1005622  0.02939623]\n",
      " [0.01520219 1.0882788 ]]\n",
      "Bb: [[0.05516877 0.0520453 ]\n",
      " [0.08508889 0.08139773]]\n",
      "x_k-1: [[-0.9792486  -1.5265119 ]\n",
      " [-0.86636007 -1.3505777 ]]\n",
      "u_k: [ 0.5360398 -0.5192681]\n",
      "x_k = Ab @ x_k_1 + Bb @ u_k: [[-1.1006446  -1.7163794 ]\n",
      " [-0.95518076 -1.4896675 ]]\n",
      "y_k = Cb @ x_k: [[-1.0158188 -1.5841626]]\n",
      "---------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[[-0.10546135, -0.1637768 ]],\n",
       "\n",
       "       [[-0.198991  , -0.30965832]],\n",
       "\n",
       "       [[-0.29179892, -0.4555015 ]],\n",
       "\n",
       "       [[-0.3652196 , -0.5694511 ]],\n",
       "\n",
       "       [[-0.4375375 , -0.6821023 ]],\n",
       "\n",
       "       [[-0.6655019 , -1.0367116 ]],\n",
       "\n",
       "       [[-0.6420449 , -1.0014658 ]],\n",
       "\n",
       "       [[-0.84966177, -1.3237844 ]],\n",
       "\n",
       "       [[-0.9118697 , -1.4214988 ]],\n",
       "\n",
       "       [[-1.0158188 , -1.5841626 ]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B, C = random_SSM(rng, 2)\n",
    "u = jax.random.normal(rng, (10, 2))\n",
    "\n",
    "L = u.shape[0]\n",
    "N = A.shape[0]\n",
    "Ab, Bb, Cb = discretize(A, B, C, step=1.0 / L)\n",
    "\n",
    "scan_SSM(Ab, Bb, Cb, u, np.zeros((N, 2)), verbose = True)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
